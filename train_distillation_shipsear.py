import os
import argparse
import yaml
import logging
from datetime import datetime

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler

# from models.CFC import AudioCfC
from models.Audio_TeacherNet import build_Audio_TeacherNet
# from models.LNN import AudioCfC
from utils.distillation_loss import DistillationLoss
from datasets.audio_dataset import AudioDataset, train_transform, validation_test_transform
from models.distillation import AudioDistillationModel
# from models.LNN import AudioCfC


def setup_logger(save_dir: str, rank: int) -> logging.Logger:
    """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
    logger = logging.getLogger('distillation')
    logger.setLevel(logging.INFO)
    logger.handlers = []  # æ¸…ç©ºå·²æœ‰ handlers
    
    # åªåœ¨ä¸»è¿›ç¨‹è®°å½•æ—¥å¿—
    if rank == 0:
        os.makedirs(save_dir, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_file = os.path.join(save_dir, f'train_{timestamp}.log')
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # æ—¥å¿—æ ¼å¼
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
    else:
        logger.addHandler(logging.NullHandler())
    
    return logger


def setup_ddp(rank: int, world_size: int, config: dict, gpu_ids: list):
    """åˆå§‹åŒ– DDP"""
    os.environ['MASTER_ADDR'] = config['distributed']['master_addr']
    os.environ['MASTER_PORT'] = config['distributed']['master_port']
    dist.init_process_group(
        backend=config['distributed']['backend'],
        rank=rank,
        world_size=world_size
    )
    local_gpu_id = gpu_ids[rank]
    torch.cuda.set_device(local_gpu_id)


def cleanup_ddp():
    """æ¸…ç† DDP"""
    dist.destroy_process_group()


def load_config(config_path: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # ç¡®ä¿æ•°å€¼ç±»å‹æ­£ç¡®
    config['training']['lr'] = float(config['training']['lr'])
    config['training']['weight_decay'] = float(config['training']['weight_decay'])
    config['distillation']['temperature'] = float(config['distillation']['temperature'])
    config['distillation']['alpha'] = float(config['distillation']['alpha'])
    
    return config


def save_checkpoint(model: nn.Module, optimizer, scheduler, epoch: int,
                    best_acc: float, save_path: str, is_best: bool = False):
    """ä¿å­˜æ£€æŸ¥ç‚¹"""
    # è·å–å­¦ç”Ÿç½‘ç»œçš„ state_dict
    if isinstance(model, DDP):
        student_state = model.module.student.state_dict()
    else:
        student_state = model.student.state_dict()
    
    checkpoint = {
        'epoch': epoch,
        'student_state_dict': student_state,
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict(),
        'best_acc': best_acc
    }
    
    torch.save(checkpoint, save_path)
    
    if is_best:
        best_path = os.path.join(os.path.dirname(save_path), 'best_student.pth')
        torch.save({'student_state_dict': student_state, 'best_acc': best_acc}, best_path)

def auto_resume_if_possible(model, optimizer, scheduler, save_dir, logger):
    """
    è‡ªåŠ¨æ£€æµ‹å¹¶æ¢å¤æœ€è¿‘checkpoint
    """
    import glob
    
    ckpts = glob.glob(os.path.join(save_dir, "checkpoint_epoch_*.pth"))
    if len(ckpts) == 0:
        logger.info("No checkpoint found, start from scratch")
        return 1, 0.0

    # æ‰¾æœ€å¤§epoch
    ckpts.sort(key=lambda x: int(x.split("_")[-1].split(".")[0]))
    latest_ckpt = ckpts[-1]

    logger.info(f"ğŸ”¥ Resume from: {latest_ckpt}")

    checkpoint = torch.load(latest_ckpt, map_location="cpu")

    # åŠ è½½å­¦ç”Ÿç½‘ç»œ
    if isinstance(model, DDP):
        model.module.student.load_state_dict(checkpoint['student_state_dict'])
    else:
        model.student.load_state_dict(checkpoint['student_state_dict'])

    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

    start_epoch = checkpoint['epoch'] + 1
    best_acc = checkpoint.get('best_acc', 0.0)

    logger.info(f"Resume epoch: {start_epoch}")
    logger.info(f"Best acc: {best_acc}")

    return start_epoch, best_acc

def get_inputs(input_data, data_type, device):
    """æ ¹æ®æ•°æ®ç±»å‹è·å–è¾“å…¥"""
    if '@' not in data_type:
        # å•ä¸€æ•°æ®ç±»å‹
        return input_data[0].to(device)
    else:
        # å¤šæ¨¡æ€è¾“å…¥
        return [data.to(device) for data in input_data]


class DistillationTrainer:
    """è’¸é¦è®­ç»ƒå™¨ (æ”¯æŒ DDP)"""
    def __init__(
        self,
        model: nn.Module,
        criterion: nn.Module,
        optimizer,
        scheduler,
        device: torch.device,
        config: dict,
        logger: logging.Logger,
        rank: int = 0,
    ):
        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.device = device
        self.config = config
        self.logger = logger
        self.rank = rank
        self.best_acc = 0.0
        self.data_type = config['dataset']['data_type']
    
    def train_epoch(self, train_loader: DataLoader, epoch: int) -> dict:
        """è®­ç»ƒä¸€ä¸ª epoch"""
        self.model.train()

        # ===== é€šçŸ¥ loss å½“å‰ epochï¼ˆç”¨äºåŠ¨æ€è’¸é¦ï¼‰=====
        if hasattr(self.criterion, "set_epoch"):
            total_epochs = self.config['training']['num_epochs']
            self.criterion.set_epoch(epoch, total_epochs)
        
        # # æ•™å¸ˆç½‘ç»œä¿æŒ eval æ¨¡å¼
        # if isinstance(self.model, DDP):
        #     self.model.module.teacher.eval()
        # else:
        #     self.model.teacher.eval()
        # æ•™å¸ˆç½‘ç»œè®­ç»ƒæ¨¡å¼æ§åˆ¶
        is_teacher_training = self.config['model']['teacher'].get('freeze', True) == False
        if not is_teacher_training:
            # æ•™å¸ˆç½‘ç»œä¿æŒ eval æ¨¡å¼
            if isinstance(self.model, DDP):
                self.model.module.teacher.eval()
            else:
                self.model.teacher.eval()
        
        total_loss = 0.0
        total_hard_loss = 0.0
        total_soft_loss = 0.0
        correct = 0
        total = 0
        valid_batches = 0
        
        for batch_idx, (input_data, labels) in enumerate(train_loader):
            # ä½¿ç”¨ä¸ train.py ç›¸åŒçš„æ–¹å¼è·å–è¾“å…¥
            inputs = get_inputs(input_data, self.data_type, self.device)
            labels = labels.to(self.device)
            
            # æ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
            # if torch.isnan(inputs).any() or torch.isinf(inputs).any():
            #     self.logger.warning(f'NaN/Inf in inputs at epoch {epoch}, batch {batch_idx}')
            #     inputs = torch.nan_to_num(inputs, nan=0.0, posinf=1.0, neginf=-1.0)
            
            # å‰å‘ä¼ æ’­
            # student_logits, stu_seq_logits, teacher_logits = self.model(inputs)
            student_logits, stu_seq_logits, fl, fg, bl, bg, x_encoder, teacher_logits, output_cnn_features, teacher_all_hidden_states = self.model(inputs)
            
            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦æœ‰å¼‚å¸¸å€¼
            if torch.isnan(student_logits).any() or torch.isinf(student_logits).any():
                self.logger.warning(f'NaN/Inf in outputs at epoch {epoch}, batch {batch_idx}')
                continue
            
            # è®¡ç®—æŸå¤±
            loss, hard_loss, soft_loss, alpha, beta, memkd_weight = self.criterion(
                # student_logits, stu_seq_logits, teacher_logits, labels
                student_logits, stu_seq_logits, fl, fg, bl, bg, x_encoder, teacher_logits, output_cnn_features, labels, teacher_all_hidden_states
            )
            
            # æ£€æŸ¥ loss æ˜¯å¦æœ‰å¼‚å¸¸å€¼
            if torch.isnan(loss) or torch.isinf(loss):
                self.logger.warning(f'Invalid loss at epoch {epoch}, batch {batch_idx}')
                continue
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            total_hard_loss += hard_loss.item()
            total_soft_loss += soft_loss.item()
            
            pred = student_logits.argmax(dim=1)
            correct += (pred == labels).sum().item()
            total += labels.size(0)
            valid_batches += 1
            
            if self.rank == 0 and batch_idx % self.config['training']['log_interval'] == 0:
                current_lr = self.optimizer.param_groups[0]['lr']
                self.logger.info(
                    f'Epoch [{epoch}] Batch [{batch_idx}/{len(train_loader)}] \
                    Loss: {loss.item():.4f}, Hard: {hard_loss.item():.4f}, Soft: {soft_loss.item():.4f} \
                    Acc: {100.*correct/total:.2f}% LR: {current_lr:.6f} \
                    Alpha: {alpha} \
                    Beta: {beta} \
                    MemKD: {memkd_weight}'
                )
        
        metrics = {
            'loss': total_loss / max(valid_batches, 1),
            'hard_loss': total_hard_loss / max(valid_batches, 1),
            'soft_loss': total_soft_loss / max(valid_batches, 1),
            'accuracy': correct / max(total, 1)
        }
        
        return metrics
    
    @torch.no_grad()
    def validate(self, val_loader: DataLoader) -> dict:
        """éªŒè¯"""
        self.model.eval()
        
        total_loss = 0.0
        correct = 0
        total = 0
        
        for input_data, labels in val_loader:
            inputs = get_inputs(input_data, self.data_type, self.device)
            labels = labels.to(self.device)
            
            # æ£€æŸ¥è¾“å…¥ï¼Œå•æ¨¡æ€è¾“å…¥ç›´æ¥æ£€æŸ¥ï¼Œ å¤šæ¨¡æ€è¾“å…¥æ£€æŸ¥æ¯ä¸ªæ¨¡æ€ï¼Œ20260121yyä¿®æ”¹
            # if torch.isnan(inputs).any() or torch.isinf(inputs).any():
            #     inputs = torch.nan_to_num(inputs, nan=0.0, posinf=1.0, neginf=-1.0)
            has_nan_inf = False
            if isinstance(inputs, list):
                # å¤šæ¨¡æ€è¾“å…¥ï¼šæ£€æŸ¥åˆ—è¡¨ä¸­çš„æ¯ä¸ªå¼ é‡
                for i, tensor in enumerate(inputs):
                    if torch.isnan(tensor).any() or torch.isinf(tensor).any():
                        has_nan_inf = True
                # ç»Ÿä¸€å¤„ç†NaN/Inf
                if has_nan_inf:
                    inputs = [torch.nan_to_num(inp, nan=0.0, posinf=1.0, neginf=-1.0) for inp in inputs]
            else:
                # å•æ¨¡æ€è¾“å…¥ï¼šç›´æ¥æ£€æŸ¥
                if torch.isnan(inputs).any() or torch.isinf(inputs).any():
                    inputs = torch.nan_to_num(inputs, nan=0.0, posinf=1.0, neginf=-1.0)
            # ä»…ä½¿ç”¨å­¦ç”Ÿç½‘ç»œ
            # student_logits, _, _ = self.model(inputs)
            student_logits, stu_seq_logits, fl, fg, bl, bg, x_encoder, teacher_logits, output_cnn_features,teacher_all_hidden_states = self.model(inputs)
            
            # æ£€æŸ¥è¾“å‡º
            if torch.isnan(student_logits).any() or torch.isinf(student_logits).any():
                continue
            
            loss = F.cross_entropy(student_logits, labels)
            
            total_loss += loss.item()
            pred = student_logits.argmax(dim=1)
            correct += (pred == labels).sum().item()
            total += labels.size(0)
        
        # DDP ä¸‹èšåˆç»“æœ
        if dist.is_initialized():
            metrics_tensor = torch.tensor([total_loss, correct, total], device=self.device)
            dist.all_reduce(metrics_tensor, op=dist.ReduceOp.SUM)
            total_loss, correct, total = metrics_tensor.tolist()
        
        num_batches = len(val_loader)
        if dist.is_initialized():
            num_batches *= dist.get_world_size()
        
        metrics = {
            'loss': total_loss / max(num_batches, 1),
            'accuracy': 100. * correct / max(total, 1)
        }
        
        return metrics
    
    def fit(self, train_loader: DataLoader, val_loader: DataLoader):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        num_epochs = self.config['training']['num_epochs']
        save_dir = self.config['save']['save_dir'] # ä¿®æ”¹ä¿å­˜ç›®å½•
        save_interval = self.config['save']['save_interval']
        
        os.makedirs(save_dir, exist_ok=True)
        
        ###############è‡ªåŠ¨resume##############
        start_epoch, self.best_acc = auto_resume_if_possible(
            self.model,
            self.optimizer,
            self.scheduler,
            save_dir,
            self.logger
        )

        # for epoch in range(1, num_epochs + 1):
        for epoch in range(start_epoch, num_epochs + 1):
            # DDP: è®¾ç½® epoch ä»¥ç¡®ä¿æ¯ä¸ª epoch çš„ shuffle ä¸åŒ
            if hasattr(train_loader.sampler, 'set_epoch'):
                train_loader.sampler.set_epoch(epoch)
            
            # è®­ç»ƒ
            train_metrics = self.train_epoch(train_loader, epoch)
            
            # éªŒè¯
            val_metrics = self.validate(val_loader)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step()
            
            # æ—¥å¿—è®°å½• (ä»…ä¸»è¿›ç¨‹)
            if self.rank == 0:
                self.logger.info(
                    f'Epoch [{epoch}/{num_epochs}] '
                    f'Train Loss: {train_metrics["loss"]:.4f}, '
                    f'Train Acc: {100.*train_metrics["accuracy"]:.2f}%, '
                    f'Val Loss: {val_metrics["loss"]:.4f}, '
                    f'Val Acc: {val_metrics["accuracy"]:.2f}%'
                )
                
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                is_best = val_metrics['accuracy'] > self.best_acc
                if is_best:
                    self.best_acc = val_metrics['accuracy']
                    self.logger.info(f'Best model saved with accuracy: {self.best_acc:.2f}%')
                
                # å®šæœŸä¿å­˜æˆ–ä¿å­˜æœ€ä½³
                if epoch % save_interval == 0 or is_best:
                    save_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch}.pth')
                    save_checkpoint(
                        self.model, self.optimizer, self.scheduler,
                        epoch, self.best_acc, save_path, is_best
                    )
                    if epoch % save_interval == 0:
                        self.logger.info(f'Checkpoint saved at epoch {epoch}')
        
        if self.rank == 0:
            self.logger.info('='*50)
            self.logger.info(f'Training finished! Best accuracy: {self.best_acc:.2f}%')
            self.logger.info('='*50)


def main_worker(rank: int, world_size: int, config: dict, gpu_ids: list):
    """å•ä¸ª GPU çš„è®­ç»ƒè¿›ç¨‹"""
    # è®¾ç½® DDP
    setup_ddp(rank, world_size, config, gpu_ids)
    
    # è·å–å½“å‰è¿›ç¨‹å¯¹åº”çš„å®é™… GPU ID
    local_gpu_id = gpu_ids[rank]
    device = torch.device(f'cuda:{local_gpu_id}')
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(config['training']['seed'] + rank)
    torch.cuda.manual_seed(config['training']['seed'] + rank)
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = config['save']['save_dir']
    os.makedirs(save_dir, exist_ok=True)
    
    # æ—¥å¿—å’Œ TensorBoard
    logger = setup_logger(save_dir, rank)
    if rank == 0:
        logger.info('='*50)
        logger.info('Distillation Training Configuration')
        logger.info('='*50)
        logger.info(f'GPUs: {gpu_ids}')
        logger.info(f'World size: {world_size}')
        logger.info(f'Dataset: {config["dataset"]["data_dir"]}')
        logger.info(f'Data type: {config["dataset"]["data_type"]}')
        logger.info(f'Batch size: {config["training"]["batch_size"]}')
        logger.info(f'Epochs: {config["training"]["num_epochs"]}')
        logger.info(f'Learning rate: {config["training"]["lr"]}')
        logger.info(f'Temperature: {config["distillation"]["temperature"]}')
        logger.info(f'Alpha: {config["distillation"]["alpha"]}')
        logger.info(f'Save dir: {save_dir}')
        logger.info('='*50)
    
    # åˆ›å»ºæ•°æ®é›† (ä½¿ç”¨ä¸ train.py ç›¸åŒçš„æ–¹å¼)
    train_dataset = AudioDataset(
        data_dir=config['dataset']['data_dir'],
        data_flag='train',
        data_type=config['dataset']['data_type'],
        transform=train_transform
    )
    
    val_dataset = AudioDataset(
        data_dir=config['dataset']['data_dir'],
        data_flag='validation',
        data_type=config['dataset']['data_type'],
        transform=validation_test_transform
    )
    
    if rank == 0:
        logger.info(f'Train dataset size: {len(train_dataset)}')
        logger.info(f'Validation dataset size: {len(val_dataset)}')
    
    # DDP Sampler
    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)
    val_sampler = DistributedSampler(val_dataset, num_replicas=world_size, rank=rank, shuffle=False)
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['training']['batch_size'],
        sampler=train_sampler,
        num_workers=config['dataset']['num_workers'],
        pin_memory=True,
        drop_last=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['training']['batch_size'],
        sampler=val_sampler,
        num_workers=config['dataset']['num_workers'],
        pin_memory=True,
        drop_last=False
    )
    
    # åˆ›å»ºæ¨¡å‹
    debug_num_classes = config['model']['num_classes']
    print(f"[DEBUG] Creating AudioDistillationModel with num_classes={debug_num_classes}")
    model = AudioDistillationModel(
        num_classes=debug_num_classes,
        teacher_pretrained=config['model']['teacher']['pretrained'],
        freeze_teacher=config['model']['teacher']['freeze'],
        teacher_checkpoint=config['model']['teacher']['checkpoint_path']
        # LNN AudioCfCä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œæ— éœ€ä¼ å…¥é¢å¤–å‚æ•°
    ).to(device)
    
    if rank == 0:
        # æ‰“å°æ¨¡å‹å‚æ•°é‡
        student_params = sum(p.numel() for p in model.student.parameters())
        teacher_params = sum(p.numel() for p in model.teacher.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        logger.info(f'Student params: {student_params:,} ({student_params/1e6:.2f}M)')
        logger.info(f'Teacher params: {teacher_params:,} ({teacher_params/1e6:.2f}M)')
        logger.info(f'Trainable params: {trainable_params:,} ({trainable_params/1e6:.2f}M)')
    
    # DDP åŒ…è£…
    model = DDP(model, device_ids=[local_gpu_id], find_unused_parameters=True)
    
    # æŸå¤±å‡½æ•°
    criterion = DistillationLoss(
        temperature=config['distillation']['temperature'],
        alpha=config['distillation']['alpha'],
        learnable_alpha=config['distillation'].get('learnable_alpha', False),
        weight_type=config['distillation'].get('weight_type', 'uniform'),
        distill_type=config['distillation'].get('distill_type', 'kl'),
        # seq_len=config['model'].get('stu_seq_len', 250),
        seq_len=config['model'].get('stu_seq_len', 16),
        # yamlå†™äº†å°±ç”¨yamlçš„å€¼ï¼Œæ²¡å†™å°±ä½¿ç”¨è¿™é‡Œé»˜è®¤çš„å€¼
    ).to(device)
    
    # ä¼˜åŒ–å™¨ (ä»…ä¼˜åŒ–å­¦ç”Ÿç½‘ç»œå’Œå¯å­¦ä¹ çš„ alpha)
    student_params = list(model.module.student.parameters())
    params_to_optimize = student_params + list(criterion.parameters())
    
    optimizer = torch.optim.AdamW(
        params_to_optimize,
        lr=config['training']['lr'],
        weight_decay=config['training']['weight_decay']
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=config['training']['num_epochs']
    )
    
    # è®­ç»ƒå™¨
    trainer = DistillationTrainer(
        model=model,
        criterion=criterion,
        optimizer=optimizer,
        scheduler=scheduler,
        device=device,
        config=config,
        logger=logger,
        rank=rank
    )
    
    if rank == 0:
        logger.info('Start training...')
    
    # å¼€å§‹è®­ç»ƒ
    trainer.fit(train_loader, val_loader)
    
    # æ¸…ç†

    cleanup_ddp()


def parse_gpu_ids(gpu_str: str) -> list:
    """è§£æ GPU ID å­—ç¬¦ä¸²"""
    return [int(x.strip()) for x in gpu_str.split(',')]


def main():
    parser = argparse.ArgumentParser(description='Audio Distillation Training')
    parser.add_argument('--config', type=str,
                        default='//media/hdd1/fubohan/Code/UATR/configs/train_distillation_shipsear.yaml',
                        help='Path to config file')
    parser.add_argument('--gpus', type=str, default=None,
                        help='æŒ‡å®šGPUï¼Œå¦‚ "0,1,2,3" æˆ– "2,3"')
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # ç¡®å®šä½¿ç”¨çš„ GPU
    if args.gpus is not None:
        gpu_ids = parse_gpu_ids(args.gpus)
    elif 'gpu_ids' in config['distributed'] and config['distributed']['gpu_ids']:
        gpu_ids = config['distributed']['gpu_ids']
    else:
        gpu_ids = list(range(torch.cuda.device_count()))
    
    # éªŒè¯ GPU ID æ˜¯å¦æœ‰æ•ˆ
    available_gpus = torch.cuda.device_count()
    for gpu_id in gpu_ids:
        if gpu_id >= available_gpus:
            raise ValueError(f'GPU {gpu_id} ä¸å­˜åœ¨ï¼Œå¯ç”¨GPUæ•°é‡: {available_gpus}')
    
    world_size = len(gpu_ids)
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(config['save']['save_dir'], exist_ok=True)
    
    print(f'Using GPUs: {gpu_ids}')
    print(f'World size: {world_size}')
    print(f'Config loaded from: {args.config}')
    
    # å¯åŠ¨å¤šè¿›ç¨‹è®­ç»ƒ
    torch.multiprocessing.spawn(
        main_worker,
        args=(world_size, config, gpu_ids),
        nprocs=world_size,
        join=True
    )


if __name__ == '__main__':
    main()