# 训练配置
training:
  num_epochs: 100
  batch_size: 32
  lr: 1e-3
  weight_decay: 0.01
  seed: 42
  log_interval: 20

# 蒸馏配置
distillation:
  temperature: 2.0
  alpha: 0.3
  learnable_alpha: true

# 模型配置
model:
  num_classes: 4
  # 教师网络 (Wav2Vec2)
  teacher:
    pretrained: true
    freeze: true
    checkpoint_path: '/media/hdd1/fubohan/Code/UATR/models/Audio_Teacher_DeepShip_622/checkpoints/Student.pth'
  # 学生网络 (CfC)
  student:
    cfc_input_size: 32
    cfc_output_size: 32
    cfc_hidden_size: 64
    pooling: 'last'

# 数据集配置 (与 train.py 保持一致)
dataset:
  data_dir: '/media/hdd1/chuxiaohui/AI4Ocean_UATR/DeepShip_622'
  data_type: 'wav'  # wav / mel / cqt / wav@mel@cqt
  num_workers: 4

# 分布式配置
distributed:
  master_addr: 'localhost'
  master_port: '12355'
  backend: 'nccl'
  gpu_ids: [3, 4, 6, 7]  # 默认使用的 GPU

# 保存配置
save:
  save_dir: 'checkpoints/distillation_weighted_sum'
  save_interval: 10