import os
import argparse
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
import torch.distributed as dist
import logging
from datetime import datetime
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
from datasets.audio_dataset import AudioDataset, train_transform, validation_test_transform
from models.LNN_Audio import liquidaudio_nano
from models.LNN import AudioCfC
# from models.CFC import AudioCfC as CFC_AudioCfC
# from models.LIQT2LNN import liquidnet_audio_tiny
# from models.LNN_Audio_encoder import AudioClassifier


def setup_logger(save_dir, rank):
    """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
    logger = logging.getLogger('train')
    logger.setLevel(logging.INFO)
    
    # åªåœ¨ä¸»è¿›ç¨‹è®°å½•æ—¥å¿—
    if rank == 0:
        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_file = os.path.join(save_dir, f'train_{timestamp}.log')
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # æ—¥å¿—æ ¼å¼
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
    else:
        # éä¸»è¿›ç¨‹ä½¿ç”¨ç©ºå¤„ç†å™¨
        logger.addHandler(logging.NullHandler())
    
    return logger


def load_config(config_path):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # ç¡®ä¿æ•°å€¼ç±»å‹æ­£ç¡®
    config['train']['lr'] = float(config['train']['lr'])
    config['train']['weight_decay'] = float(config['train']['weight_decay'])
    
    return config


def setup(rank, world_size, config, gpu_ids):
    """åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    os.environ['MASTER_ADDR'] = config['distributed']['master_addr']
    os.environ['MASTER_PORT'] = config['distributed']['master_port']
    dist.init_process_group(
        backend=config['distributed']['backend'],
        rank=rank,
        world_size=world_size
    )
    # è®¾ç½®å½“å‰è¿›ç¨‹ä½¿ç”¨çš„GPU
    local_gpu_id = gpu_ids[rank]
    torch.cuda.set_device(local_gpu_id)


def cleanup():
    """æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    dist.destroy_process_group()

def load_checkpoint_from_path(checkpoint_path, device):
    """ä»æŒ‡å®šè·¯å¾„åŠ è½½æ£€æŸ¥ç‚¹ï¼ˆåœ¨ä¸»å‡½æ•°ä¸­è°ƒç”¨ï¼‰"""
    try:
        print(f"Loading checkpoint '{checkpoint_path}'...")
        checkpoint = torch.load(checkpoint_path, map_location=device)
        
        # è·å–checkpointä¿¡æ¯
        epoch = checkpoint.get('epoch', 0)
        accuracy = checkpoint.get('accuracy', 0.0)
        model_state_dict = checkpoint.get('model_state_dict')
        optimizer_state_dict = checkpoint.get('optimizer_state_dict')
        
        print(f"Loaded checkpoint: epoch {epoch + 1}, accuracy: {accuracy:.2f}%")
        
        return {
            'epoch': epoch,
            'accuracy': accuracy,
            'model_state_dict': model_state_dict,
            'optimizer_state_dict': optimizer_state_dict,
            'loaded': True
        }
        
    except Exception as e:
        print(f"Error loading checkpoint: {e}")
        return {'loaded': False}

def apply_checkpoint_to_model(model, optimizer, checkpoint_data, target_lr=None):
    """å°†æ£€æŸ¥ç‚¹æ•°æ®åº”ç”¨åˆ°æ¨¡å‹å’Œä¼˜åŒ–å™¨ï¼ˆåœ¨è®­ç»ƒè¿›ç¨‹ä¸­è°ƒç”¨ï¼‰
    
    Args:
        model: æ¨¡å‹
        optimizer: ä¼˜åŒ–å™¨
        checkpoint_data: æ£€æŸ¥ç‚¹æ•°æ®å­—å…¸
        target_lr: ç›®æ ‡å­¦ä¹ ç‡ï¼ˆå¦‚æœæä¾›ï¼Œå°†è¦†ç›–æ£€æŸ¥ç‚¹ä¸­çš„å­¦ä¹ ç‡ï¼‰
    """
    if not checkpoint_data['loaded']:
        return 0
    
    try:
        # åŠ è½½æ¨¡å‹æƒé‡
        if hasattr(model, 'module'):  # DDPæ¨¡å‹
            model.module.load_state_dict(checkpoint_data['model_state_dict'])
        else:
            model.load_state_dict(checkpoint_data['model_state_dict'])
        
        # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
        if (optimizer is not None and 
            checkpoint_data['optimizer_state_dict'] is not None):
            optimizer.load_state_dict(checkpoint_data['optimizer_state_dict'])
        
        # å¦‚æœæŒ‡å®šäº†ç›®æ ‡å­¦ä¹ ç‡ï¼Œåˆ™è¦†ç›–ä¼˜åŒ–å™¨ä¸­çš„å­¦ä¹ ç‡
        if target_lr is not None:
            for param_group in optimizer.param_groups:
                param_group['lr'] = target_lr
            print(f"âœ“ å­¦ä¹ ç‡å·²é‡ç½®ä¸º: {target_lr}")
        
        print(f"Successfully applied checkpoint to model and optimizer")
        return checkpoint_data['epoch'] + 1  # è¿”å›ä¸‹ä¸€ä¸ªepoch
        
    except Exception as e:
        print(f"Error applying checkpoint: {e}")
        return 0


def train(rank, world_size, config, gpu_ids, checkpoint_data=None):
    # åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
    setup(rank, world_size, config, gpu_ids)
    
    # è·å–å½“å‰è¿›ç¨‹å¯¹åº”çš„å®é™…GPU ID
    local_gpu_id = gpu_ids[rank]
    device = torch.device(f'cuda:{local_gpu_id}')
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = config['save']['save_dir']
    os.makedirs(save_dir, exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—è®°å½•å™¨
    logger = setup_logger(save_dir, rank)
    
    # è®°å½•é…ç½®ä¿¡æ¯
    if rank == 0:
        logger.info('='*50)
        logger.info('Training Configuration')
        logger.info('='*50)
        logger.info(f'GPUs: {gpu_ids}')
        logger.info(f'World size: {world_size}')
        logger.info(f'Dataset: {config["dataset"]["data_dir"]}')
        logger.info(f'Data type: {config["dataset"]["data_type"]}')
        logger.info(f'Batch size: {config["train"]["batch_size"]}')
        logger.info(f'Epochs: {config["train"]["epochs"]}')
        logger.info(f'Learning rate: {config["train"]["lr"]}')
        logger.info(f'Weight decay: {config["train"]["weight_decay"]}')
        logger.info(f'Save dir: {save_dir}')
        logger.info('='*50)
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = AudioDataset(
        data_dir=config['dataset']['data_dir'],
        data_flag='train',
        data_type=config['dataset']['data_type'],
        transform=train_transform
    )
    
    val_dataset = AudioDataset(
        data_dir=config['dataset']['data_dir'],
        data_flag='validation',
        data_type=config['dataset']['data_type'],
        transform=validation_test_transform
    )
    
    if rank == 0:
        logger.info(f'Train dataset size: {len(train_dataset)}')
        logger.info(f'Validation dataset size: {len(val_dataset)}')
    
    # åˆ†å¸ƒå¼é‡‡æ ·å™¨
    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)
    val_sampler = DistributedSampler(val_dataset, num_replicas=world_size, rank=rank, shuffle=False)
    
    # æ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['train']['batch_size'],
        sampler=train_sampler,
        num_workers=config['dataset']['num_workers'],
        pin_memory=True,
        drop_last=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['train']['batch_size'],
        sampler=val_sampler,
        num_workers=config['dataset']['num_workers'],
        pin_memory=True,
        drop_last=False
    )
    
    # åˆå§‹åŒ–æ¨¡å‹
    num_classes = config['model']['num_classes']
    model = AudioCfC(num_classes=num_classes)
    model = model.to(device)
    model = DDP(model, device_ids=[local_gpu_id], find_unused_parameters=True)
    
    # è®°å½•æ¨¡å‹ä¿¡æ¯
    if rank == 0:
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        logger.info(f'Total parameters: {total_params / 1e6:.2f}M')
        logger.info(f'Trainable parameters: {trainable_params / 1e6:.2f}M')
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config['train']['lr'],
        weight_decay=config['train']['weight_decay']
    )
    scheduler = optim.lr_scheduler.StepLR(
        optimizer,
        step_size=config['train']['step_size'],
        gamma=config['train']['gamma']
    )
    
    data_type = config['dataset']['data_type']
    
        # åº”ç”¨æ–­ç‚¹æ•°æ®
    start_epoch = 0
    if checkpoint_data is None:
        checkpoint_data = {'loaded': False}
    
    if checkpoint_data and checkpoint_data.get('loaded', False) and rank == 0:
        # åªåœ¨ä¸»è¿›ç¨‹ä¸­åº”ç”¨æ–­ç‚¹ï¼Œå¹¶ä¼ å…¥é…ç½®æ–‡ä»¶ä¸­çš„å­¦ä¹ ç‡ä»¥è¦†ç›–æ–­ç‚¹ä¸­çš„å­¦ä¹ ç‡
        start_epoch = apply_checkpoint_to_model(model, optimizer, checkpoint_data, target_lr=config['train']['lr'])
    
    # DDPåŒæ­¥å„è¿›ç¨‹çš„æ–­ç‚¹ä¿¡æ¯
    if dist.is_initialized():
        start_epoch_tensor = torch.tensor([start_epoch], device=device)
        dist.broadcast(start_epoch_tensor, src=0)
        start_epoch = start_epoch_tensor.item()

    # è®­ç»ƒå¾ªç¯
    best_acc = 0.0
    logger.info('Start training...')
    
    for epoch in range(config['train']['epochs']):
        model.train()
        train_sampler.set_epoch(epoch)
        
        total_loss = 0.0
        correct = 0
        total = 0
        valid_batches = 0
        
        for batch_idx, (input_data, labels) in enumerate(train_loader):
            inputs = get_inputs(input_data, data_type, device)
            labels = labels.to(device)
            
            # æ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
            if torch.isnan(inputs).any() or torch.isinf(inputs).any():
                logger.warning(f'NaN/Inf in inputs at epoch {epoch}, batch {batch_idx}')
                inputs = torch.nan_to_num(inputs, nan=0.0, posinf=1.0, neginf=-1.0)
            
            optimizer.zero_grad()
            outputs, sequence_output = model(inputs)
            
            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦æœ‰å¼‚å¸¸å€¼
            if torch.isnan(outputs).any() or torch.isinf(outputs).any():
                logger.warning(f'NaN/Inf in outputs at epoch {epoch}, batch {batch_idx}')
                continue
            # åœ¨ç¬¬217è¡Œä¹‹å‰æ·»åŠ æ ‡ç­¾æ£€æŸ¥
            # print(f"Labels range: {labels.min().item()} to {labels.max().item()}")
            # print(f"Expected range: 0 to {config['model']['num_classes'] - 1}")
            # unique_labels = torch.unique(labels)
            # print(f"Unique labels: {unique_labels}")
            loss = criterion(outputs, labels)
            
            # æ£€æŸ¥lossæ˜¯å¦æœ‰å¼‚å¸¸å€¼
            if torch.isnan(loss) or torch.isinf(loss):
                logger.warning(f'Invalid loss at epoch {epoch}, batch {batch_idx}')
                continue
            
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            valid_batches += 1
            
            if rank == 0 and batch_idx % config['train']['log_interval'] == 0:
                current_lr = optimizer.param_groups[0]['lr']
                logger.info(f'Epoch [{epoch+1}/{config["train"]["epochs"]}] '
                           f'Batch [{batch_idx}/{len(train_loader)}] '
                           f'Loss: {loss.item():.4f} Acc: {100.*correct/total:.2f}% '
                           f'LR: {current_lr:.6f}')
        
        # åªåœ¨è°ƒåº¦å™¨å­˜åœ¨æ—¶æ‰æ›´æ–°å­¦ä¹ ç‡
        if scheduler is not None:
            scheduler.step()
        
        # éªŒè¯
        val_acc = validate(model, val_loader, device, data_type, logger)
        
        if rank == 0:
            avg_loss = total_loss / max(valid_batches, 1)
            train_acc = 100. * correct / max(total, 1)
            logger.info(f'Epoch [{epoch+1}/{config["train"]["epochs"]}] '
                       f'Train Loss: {avg_loss:.4f} '
                       f'Train Acc: {train_acc:.2f}% Val Acc: {val_acc:.2f}%')
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_acc:
                best_acc = val_acc
                save_checkpoint(
                    model, optimizer, epoch, best_acc,
                    os.path.join(save_dir, 'best_model.pth')
                )
                logger.info(f'Best model saved with accuracy: {best_acc:.2f}%')
            
            # å®šæœŸä¿å­˜æ¨¡å‹ æ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡
            if (epoch + 1) % config['save']['save_interval'] == 0:
                save_checkpoint(
                    model, optimizer, epoch, val_acc,
                    os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pth')
                )
                logger.info(f'Checkpoint saved at epoch {epoch+1}')
    
    if rank == 0:
        logger.info('='*50)
        logger.info(f'Training finished! Best accuracy: {best_acc:.2f}%')
        logger.info('='*50)
    
    cleanup()


def get_inputs(input_data, data_type, device):
    """æ ¹æ®æ•°æ®ç±»å‹è·å–è¾“å…¥"""
    if '@' not in data_type:
        # å•ä¸€æ•°æ®ç±»å‹
        return input_data[0].to(device)
    else:
        # å¤šæ¨¡æ€è¾“å…¥
        return [data.to(device) for data in input_data]


def validate(model, val_loader, device, data_type, logger=None):
    """éªŒè¯å‡½æ•°"""
    model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for input_data, labels in val_loader:
            inputs = get_inputs(input_data, data_type, device)
            labels = labels.to(device)
            
            # æ£€æŸ¥è¾“å…¥
            if torch.isnan(inputs).any() or torch.isinf(inputs).any():
                inputs = torch.nan_to_num(inputs, nan=0.0, posinf=1.0, neginf=-1.0)
            
            outputs, sequence_output = model(inputs)
            
            # æ£€æŸ¥è¾“å‡º
            if torch.isnan(outputs).any() or torch.isinf(outputs).any():
                continue
            
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
    
    # èšåˆæ‰€æœ‰è¿›ç¨‹çš„ç»“æœ
    correct_tensor = torch.tensor([correct], device=device)
    total_tensor = torch.tensor([total], device=device)
    dist.all_reduce(correct_tensor, op=dist.ReduceOp.SUM)
    dist.all_reduce(total_tensor, op=dist.ReduceOp.SUM)
    
    accuracy = 100. * correct_tensor.item() / max(total_tensor.item(), 1)
    return accuracy


def save_checkpoint(model, optimizer, epoch, acc, path):
    """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.module.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'accuracy': acc,
    }, path)
    print(f"ğŸ“ Model saved to: {path}")


def parse_gpu_ids(gpu_str):
    """è§£æGPU IDå­—ç¬¦ä¸²"""
    return [int(x.strip()) for x in gpu_str.split(',')]


def main():
    parser = argparse.ArgumentParser(description='DDP Training for Audio Classification')
    parser.add_argument('--config', type=str, default='configs/train_LNN_deepship.yaml',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--gpus', type=str, default=None,
                        help='æŒ‡å®šGPUï¼Œå¦‚ "0,1,2,3" æˆ– "2,3"')
    parser.add_argument('--resume', type=str, default=None,
                        help='æ–­ç‚¹æ–‡ä»¶è·¯å¾„')
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    import os
    config_path = args.config if os.path.isabs(args.config) else os.path.join(os.path.dirname(__file__), args.config)
    config = load_config(config_path)
    
    # ç¡®å®šä½¿ç”¨çš„GPU
    if args.gpus is not None:
        gpu_ids = parse_gpu_ids(args.gpus)
    elif 'gpu_ids' in config['distributed'] and config['distributed']['gpu_ids']:
        gpu_ids = config['distributed']['gpu_ids']
    else:
        gpu_ids = list(range(torch.cuda.device_count()))
    
    # éªŒè¯GPU IDæ˜¯å¦æœ‰æ•ˆ
    available_gpus = torch.cuda.device_count()
    for gpu_id in gpu_ids:
        if gpu_id >= available_gpus:
            raise ValueError(f'GPU {gpu_id} ä¸å­˜åœ¨ï¼Œå¯ç”¨GPUæ•°é‡: {available_gpus}')
    
    world_size = len(gpu_ids)
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(config['save']['save_dir'], exist_ok=True)
    # ==================== ä¸»å‡½æ•°ä¸­æ–­ç‚¹åŠ è½½é€»è¾‘ ====================
    checkpoint_data = {'loaded': False}
    
    if args.resume:
        # å¤„ç†ç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
        resume_path = args.resume
        if not os.path.isabs(resume_path):
            resume_path = os.path.join(os.path.dirname(__file__), resume_path)
        
        # æ£€æŸ¥æ–­ç‚¹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(resume_path):
            print(f"Warning: Resume checkpoint '{resume_path}' does not exist. Starting from scratch.")
        else:
            print(f"Resume checkpoint found: {resume_path}")
            
            # åœ¨ä¸»å‡½æ•°ä¸­åŠ è½½æ–­ç‚¹æ–‡ä»¶
            try:
                # ä½¿ç”¨CPUè®¾å¤‡åŠ è½½checkpointï¼Œé¿å…GPUå†…å­˜é—®é¢˜
                cpu_device = torch.device('cpu')
                checkpoint_data = load_checkpoint_from_path(resume_path, cpu_device)
                
                if checkpoint_data['loaded']:
                    print(f"âœ“ æˆåŠŸåœ¨mainå‡½æ•°ä¸­åŠ è½½æ–­ç‚¹ä¿¡æ¯")
                    print(f"  - Checkpoint Epoch: {checkpoint_data['epoch'] + 1}")
                    print(f"  - Checkpoint Accuracy: {checkpoint_data['accuracy']:.2f}%")
                else:
                    print(f"âœ— æ–­ç‚¹åŠ è½½å¤±è´¥ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ")
                    
            except Exception as e:
                print(f"âœ— æ–­ç‚¹å¤„ç†é”™è¯¯: {e}")
                print(f"  å°†ä»å¤´å¼€å§‹è®­ç»ƒ")
                checkpoint_data = {'loaded': False}
    
    print(f'Using GPUs: {gpu_ids}')
    print(f'World size: {world_size}')
    print(f'Config loaded from: {args.config}')
    if checkpoint_data['loaded']:
        print(f'Resume from checkpoint: {resume_path}')
    else:
        print('Starting training from scratch')
    print(f'Using GPUs: {gpu_ids}')
    print(f'World size: {world_size}')
    print(f'Config loaded from: {args.config}')
    
    # å¯åŠ¨å¤šè¿›ç¨‹è®­ç»ƒ
    torch.multiprocessing.spawn(
        train,
        args=(world_size, config, gpu_ids, checkpoint_data),
        nprocs=world_size,
        join=True
    )


if __name__ == '__main__':
    main()